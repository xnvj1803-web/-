
# 矩阵分解方法比较：凸方法与非凸方法

## 实验概述

本项目旨在使用 **MovieLens 20M 数据集** 比较两种矩阵分解方法的效果。我们实现并评估了以下两种方法：

1. **凸方法**：核范数最小化（奇异值阈值算法）
2. **非凸方法**：交替最小二乘法（ALS）

实验使用 **5折交叉验证**，并以 **均方根误差（RMSE）** 为主要评价指标。

## 项目目标

- 比较凸方法与非凸方法在矩阵分解中的表现。
- 对两种方法进行超参数调优，以优化 RMSE。
- 分析正则化系数、隐因子维度等参数变化对模型性能的影响。

## 实验过程

### 初期问题：
- **非凸方法（ALS）**：过拟合（训练 RMSE ≈ 0.4，测试 RMSE ≈ 1.3）。
- **凸方法**：表现差（RMSE ≈ 3.6，接近随机预测）。

### 遇到的挑战：
- **非凸方法**：由于正则化参数 λ 设置过小（λ=0.1），出现严重过拟合，方差较大。
- **凸方法**：提前收敛，初始阈值设置不当（τ=5√(mn)）。

### 算法改进：
- **凸方法**：修正了 SVT 和 SoftImpute 算法。
- **非凸方法**：加入了偏置项和早停机制。

## 实验结果分析

### 最终 RMSE 结果

| 方法                 | 调优后 RMSE  | 最终 RMSE   | 改进幅度 (%)   | 稳定性     |
|----------------------|--------------|-------------|----------------|------------|
| **基线**（全局均值）  | 1.0642       | 1.0633      | -              | 稳定       |
| **非凸方法**（ALS）   | 0.9976       | 1.1376      | +6.3%/-7.0%    | 不稳定     |
| **凸方法**（SVT）     | 0.9430       | 1.0099      | +11.4%/+5.0%   | 中等稳定性 |
| **凸方法**（SoftImpute）| 0.9419       | 1.0092      | +11.5%/+5.1%   | 中等稳定性（最佳）|

### 关键发现

1. **凸方法**：
   - 对参数敏感，特别是正则化系数。
   - 计算成本高，难以扩展。

2. **非凸方法**：
   - 易陷入局部最优解。
   - 需要仔细调整正则化和使用早停机制。

3. **数据集特点**：
   - 数据稀疏度高（>98%）。
   - 基线方法（全局均值）已经有较好的表现，因此高级方法难以超越。

### 遇到的挑战
- **内存问题**：稠密矩阵存储过于庞大。解决方案：使用稀疏矩阵和批量处理数据。
- **数值稳定性问题**：梯度爆炸和 NaN 值的出现。解决方案：梯度裁剪、动态调整学习率。
- **算法收敛问题**：凸方法提前收敛，非凸方法收敛过慢。解决方案：调整收敛条件，改进算法实现。

## 参数分析

1. **正则化参数（λ）**：
   - λ 过小（λ=0.1）：过拟合严重。
   - λ 过大（λ=10.0）：欠拟合，预测值接近均值。
   - 最优范围（λ=0.5-2.0）。

2. **隐因子维度**：
   - 隐因子维度过小（<10）：表达能力不足。
   - 隐因子维度过大（>50）：过拟合风险增加。
   - 推荐范围：10-20。

3. **学习率**：
   - 学习率过大：导致数值不稳定（梯度爆炸）。
   - 学习率过小：收敛速度慢。
   - 推荐使用自适应学习率。

## 理论与实际结果对比

### 预期结果

- **凸方法**：应收敛到全局最优解，能较好地抵抗噪声。
- **非凸方法**：可能会陷入局部最优，但计算效率更高。

### 实际结果

- **凸方法**：由于算法实现问题和参数设置不当，未能如预期表现。
- **非凸方法**：由于正则化不足，过拟合问题严重。

## 可视化结果

以下是实验中的关键可视化图：

### 1. 迭代过程中的 RMSE 比较
第一组图展示了两种方法（凸方法与非凸方法）在多个迭代中的训练 RMSE，显示了学习曲线和最终表现：


![High Dim Convergence](Figure1.png)


### 2. 不同交叉验证折上的方法表现
第二组图展示了不同交叉验证折上的方法表现：

![性能比较](https://raw.githubusercontent.com/username/repository/branch/images/703520c47b331a5ed467f6c30a6ef14.png)

---

## 安装与使用

为了复制实验结果，请按以下步骤操作：

1. 克隆该仓库：
   ```bash
   git clone https://github.com/username/repository.git
   cd repository
   ```

2. 安装所需的依赖库：
   ```bash
   pip install -r requirements.txt
   ```

3. 运行实验：
   ```bash
   python matrix_factorization_experiment.py
   ```

---

你可以修改参数并使用该数据集进行更多实验，探索不同的超参数对模型性能的影响。
